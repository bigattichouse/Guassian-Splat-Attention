{
  "experiment_name": "splatflow_fixed_ultra_conservative_1749595195",
  "hardware_tier": "ultra_conservative",
  "dataset_config": "conservative",
  "training_summary": {
    "config": {
      "model_dim": 256,
      "num_layers": 2,
      "num_splats": 5,
      "max_splats": 24,
      "max_seq_len": 2048,
      "dropout": 0.1,
      "epochs": 500,
      "batch_size": 3,
      "seq_length": 1024,
      "target_sequences": 256,
      "learning_rate": 0.0003,
      "weight_decay": 0.01,
      "use_progressive_training": true,
      "warmup_epochs": 3,
      "eval_interval": 5,
      "eval_max_length": 50,
      "eval_temperature": 0.8,
      "eval_top_k": 50,
      "log_interval": 5,
      "save_interval": 10,
      "checkpoint_dir": "experiments/splatflow_fixed_ultra_conservative_1749595195/checkpoints",
      "dataset_name": "enhanced_real",
      "steps_per_epoch": 50,
      "gradient_accumulation_steps": 8,
      "mixed_precision": true,
      "gradient_checkpointing": true,
      "disable_adaptive_birth": true,
      "max_births_per_epoch": 0,
      "birth_cooldown": 999,
      "dataset_config": "conservative",
      "enable_detailed_monitoring": false
    },
    "total_epochs": 24,
    "total_steps": 1246,
    "best_loss": 5.953253993988037,
    "final_model_stats": {
      "epoch": 23,
      "total_splats": 14,
      "total_healthy_splats": 14,
      "health_percentage": 100.0,
      "overall_health": "\ud83d\udfe2 HEALTHY",
      "layer_stats": [
        {
          "layer_idx": 0,
          "num_splats": 7,
          "healthy_splats": 7,
          "avg_usefulness": 5.0,
          "avg_trajectory_influence": 0.25925740019551347,
          "trajectory_strength": 0.6456562876701355,
          "coverage_efficiency": 0.0,
          "birth_stats": {
            "total_births": 2,
            "total_deaths": 0,
            "births_this_epoch": 2,
            "pending_requests": 844,
            "cooldown_remaining": 0,
            "birth_reasons": {
              "coverage_gap": 1,
              "radius_limit_reached": 1
            },
            "max_splats": 24,
            "max_radius": 10.0,
            "coverage_stats": {
              "gaps_detected": 1,
              "clusters_found": 3,
              "coverage_threshold": 0.1,
              "min_cluster_size": 3
            }
          },
          "health_status": "\ud83d\udfe2 HEALTHY"
        },
        {
          "layer_idx": 1,
          "num_splats": 7,
          "healthy_splats": 7,
          "avg_usefulness": 5.0,
          "avg_trajectory_influence": 1.3967266253062658,
          "trajectory_strength": 0.7109494805335999,
          "coverage_efficiency": 0.0,
          "birth_stats": {
            "total_births": 2,
            "total_deaths": 0,
            "births_this_epoch": 2,
            "pending_requests": 8688,
            "cooldown_remaining": 0,
            "birth_reasons": {
              "trajectory_bottleneck": 1,
              "radius_limit_reached": 1
            },
            "max_splats": 24,
            "max_radius": 10.0,
            "coverage_stats": {
              "gaps_detected": 0,
              "clusters_found": 0,
              "coverage_threshold": 0.1,
              "min_cluster_size": 3
            }
          },
          "health_status": "\ud83d\udfe2 HEALTHY"
        }
      ],
      "trajectory_stats": {
        "layer_flow_magnitudes": {
          "0": 0.19554060697555542,
          "1": 3.864118814468384
        },
        "total_layers_with_flow": 2,
        "max_flow_magnitude": 3.864118814468384,
        "avg_flow_magnitude": 2.0298297107219696,
        "guidance": {
          "guidance_strengths_by_layer": [
            0.6179112195968628,
            0.6527330279350281
          ],
          "avg_guidance_strength": 0.6353221237659454,
          "max_guidance_strength": 0.6527330279350281,
          "guidance_active_layers": 2
        },
        "cache": {
          "cache_size": 25,
          "cache_hits": 5635,
          "cache_misses": 2349,
          "hit_rate": 0.7057865731462926,
          "total_requests": 7984
        }
      },
      "model_info": {
        "num_layers": 2,
        "model_dim": 256,
        "num_splats_per_layer": 5,
        "max_seq_len": 2048
      }
    },
    "training_stats": [
      {
        "epoch": 0,
        "loss": 8.37967474937439,
        "lr": 0.00029999733521557923,
        "time": 22.35492205619812,
        "steps": 50
      },
      {
        "epoch": 1,
        "loss": 6.212645998001099,
        "lr": 0.0002999893409675172,
        "time": 12.952925205230713,
        "steps": 50
      },
      {
        "epoch": 2,
        "loss": 6.0961525249481205,
        "lr": 0.00029997601757141283,
        "time": 10.419247150421143,
        "steps": 50
      },
      {
        "epoch": 3,
        "loss": 6.041439762115479,
        "lr": 0.00029995736555325065,
        "time": 9.61888599395752,
        "steps": 50
      },
      {
        "epoch": 4,
        "loss": 6.031431818008423,
        "lr": 0.0002999333856493801,
        "time": 10.742763996124268,
        "steps": 50
      },
      {
        "epoch": 5,
        "loss": 6.017788467407226,
        "lr": 0.000299904078806487,
        "time": 9.620356559753418,
        "steps": 50
      },
      {
        "epoch": 6,
        "loss": 5.984536380767822,
        "lr": 0.00029986944618155527,
        "time": 10.085796117782593,
        "steps": 50
      },
      {
        "epoch": 7,
        "loss": 6.008687305450439,
        "lr": 0.00029982948914182193,
        "time": 10.170676231384277,
        "steps": 50
      },
      {
        "epoch": 8,
        "loss": 5.982873249053955,
        "lr": 0.0002997842092647226,
        "time": 9.932964324951172,
        "steps": 50
      },
      {
        "epoch": 9,
        "loss": 5.991765003204346,
        "lr": 0.00029973360833782906,
        "time": 9.739568710327148,
        "steps": 50
      },
      {
        "epoch": 10,
        "loss": 5.970444688796997,
        "lr": 0.0002996776883587792,
        "time": 9.636561632156372,
        "steps": 50
      },
      {
        "epoch": 11,
        "loss": 5.968213243484497,
        "lr": 0.0002996164515351975,
        "time": 9.637244462966919,
        "steps": 50
      },
      {
        "epoch": 12,
        "loss": 5.970312023162842,
        "lr": 0.00029954990028460975,
        "time": 9.673035383224487,
        "steps": 50
      },
      {
        "epoch": 13,
        "loss": 5.972967290878296,
        "lr": 0.0002994780372343453,
        "time": 9.831459760665894,
        "steps": 50
      },
      {
        "epoch": 14,
        "loss": 5.954304895401001,
        "lr": 0.00029940086522143444,
        "time": 11.23042368888855,
        "steps": 50
      },
      {
        "epoch": 15,
        "loss": 5.98785101890564,
        "lr": 0.0002993183872924955,
        "time": 22.373947381973267,
        "steps": 50
      },
      {
        "epoch": 16,
        "loss": 5.984706630706787,
        "lr": 0.0002992306067036163,
        "time": 58.00705432891846,
        "steps": 50
      },
      {
        "epoch": 17,
        "loss": 5.963993110656738,
        "lr": 0.0002991375269202236,
        "time": 125.47386956214905,
        "steps": 50
      },
      {
        "epoch": 18,
        "loss": 5.953253993988037,
        "lr": 0.00029903915161694856,
        "time": 125.88443398475647,
        "steps": 50
      },
      {
        "epoch": 19,
        "loss": 5.9834933185577395,
        "lr": 0.00029893548467747996,
        "time": 125.14545369148254,
        "steps": 50
      },
      {
        "epoch": 20,
        "loss": 5.97049635887146,
        "lr": 0.00029882653019441016,
        "time": 124.41591191291809,
        "steps": 50
      },
      {
        "epoch": 21,
        "loss": 5.981978893280029,
        "lr": 0.0002987122924690761,
        "time": 124.57256984710693,
        "steps": 50
      },
      {
        "epoch": 22,
        "loss": 5.970296440124511,
        "lr": 0.0002985927760113873,
        "time": 124.61915826797485,
        "steps": 50
      },
      {
        "epoch": 23,
        "loss": 5.966320352554321,
        "lr": 0.0002984679855396489,
        "time": 124.67302584648132,
        "steps": 50
      }
    ],
    "device": "cuda"
  },
  "completed_at": "2025-06-10T18:01:13.290084",
  "context_length": 1024,
  "fixes_applied": [
    "Memory-safe configurations",
    "Conservative splat birth control",
    "Gradient accumulation for small batches",
    "Progressive layer training"
  ]
}